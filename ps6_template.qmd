---
title: "Problem Set 6 - Waze Shiny Dashboard"
author: "Peter Ganong, Maggie Shi, and Andre Oviedo"
date: today
format: 
  pdf:
    include-in-header: 
       text: |
         \usepackage{fvextra}
         \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
include-before-body:
  text: |
    \RecustomVerbatimEnvironment{verbatim}{Verbatim}{
      showspaces = false,
      showtabs = false,
      breaksymbolleft={},
      breaklines
    }
---
1. **ps6:** Due Sat 23rd at 5:00PM Central. Worth 100 points (80 points from questions, 10 points for correct submission and 10 points for code style) + 10 extra credit. 

We use (`*`) to indicate a problem that we think might be time consuming. 

# Steps to submit (10 points on PS6) {-}

1. "This submission is my work alone and complies with the 30538 integrity
policy." Add your initials to indicate your agreement: \*\*\H\L\*\*
2. "I have uploaded the names of anyone I worked with on the problem set **[here](https://docs.google.com/forms/d/185usrCREQaUbvAXpWhChkjghdGgmAZXA3lPWpXLLsts/edit)**"  \*\*\_\_\*\* (2 point)
3. Late coins used this pset: \*\*\_\_\*\* Late coins left after submission: \*\*\_\_\*\*

4. Before starting the problem set, make sure to read and agree to the terms of data usage for the Waze data [here](https://canvas.uchicago.edu/courses/59054/quizzes/130617).

5. Knit your `ps6.qmd` as a pdf document and name it `ps6.pdf`.
6. Submit your `ps6.qmd`, `ps6.pdf`, `requirements.txt`, and all created folders (we will create three Shiny apps so you will have at least three additional folders) to the gradescope repo assignment (5 points).
7. Submit `ps6.pdf` and also link your Github repo via Gradescope (5 points)
8. Tag your submission in Gradescope. For the Code Style part (10 points) please tag the whole correspondingsection for the code style rubric.

*Notes: see the [Quarto documentation (link)](https://quarto.org/docs/authoring/figures.html) for directions on inserting images into your knitted document.*

*IMPORTANT: For the App portion of the PS, in case you can not arrive to the expected functional dashboard we will need to take a look at your `app.py` file. You can use the following code chunk template to "import" and print the content of that file. Please, don't forget to also tag the corresponding code chunk as part of your submission!*

```{python}
#| echo: true
#| eval: false

def print_file_contents(file_path):
    """Print contents of a file."""
    try:
        with open(file_path, 'r') as f:
            content = f.read()
            print("```python")
            print(content)
            print("```")
    except FileNotFoundError:
        print("```python")
        print(f"Error: File '{file_path}' not found")
        print("```")
    except Exception as e:
        print("```python") 
        print(f"Error reading file: {e}")
        print("```")

print_file_contents("./top_alerts_map_byhour/app.py") # Change accordingly
```

```{python} 
#| echo: false

# Import required packages.
import pandas as pd
import altair as alt 
import pandas as pd
from datetime import date
import numpy as np
alt.data_transformers.disable_max_rows() 

import json
```

# Background {-}

## Data Download and Exploration (20 points){-} 

1. 

```{python}
import os

#set wd and load in data
path = r"/Users/hallielovin/Documents/GitHub/ps6"

waze_sample = r"waze_data_sample.csv"

waze_sample_df = pd.read_csv(os.path.join(path, waze_sample))
```

```{python}
#find the column names
print(waze_sample_df.columns)
```

The variable names are: Unnamed:0, city, confidence, nthumbsup, street, uuid, country, tyoe, subtype, roadType, reliability, magvar, reportRating, ts, geo, and geoWKT. 

```{python}
#find the data types
print(waze_sample_df.dtypes)
```

The data types are: 
Unnamed: 0: Nominal 
city: Nominal 
confidence: Ordinal 
nThumbsUp: Quantitative 
street: Nominal 
uuid: Nominal 
country: Nominal 
type: Nominal 
Subtype: Nominal 
roadType: Nominal 
reliability: Ordinal
magvar: Quantitative
reportRating: Ordinal
ts: Temporal
geo: Quantitative
geoWKT: Quantitative

2. 

```{python}
#load in the waze data 
waze = r"waze_data.csv"

waze_df = pd.read_csv(os.path.join(path, waze))
```

```{python}
#pull out all the varaibles and make a list 
variables = waze_df.columns

#pull out all the null values in each column and make a list 
null_counts = waze_df.isnull().sum().reset_index()
null_counts.columns = ["variables", "null"]

#pull out all the none null
non_null_counts = waze_df.notnull().sum().reset_index()
non_null_counts.columns = ["variables", "not null"]
```

```{python}
#create a df with the count data
null_data = pd.melt(null_counts.merge(non_null_counts, on="variables"),id_vars="variables", value_vars=["null", "not null"], var_name="status", value_name= "count")
```

```{python}
#make a chart 
alt.Chart(null_data).mark_bar().encode(
    x=alt.X("variables:N"),
    y=alt.Y("count:Q"),
    color="status:N"
).properties(
  title = "Null Status in Data"
)
```

nThumbsUp, street, and subtypes all have null values. nThumbsUp has the highest share of missing data. 

3. 

```{python}
#print the unique values for type and subtype 
print(waze_df["type"].unique())
print(waze_df["subtype"].unique())
```

```{python}
#find out how many types have a subtype that is NA
na_subtype = waze_df[waze_df["subtype"].isna()]["type"].unique()

len(na_subtype)
```

There are 4 types that have an NA for subtype.
 
```{python}
#print the combos of type and subtype 
combo = waze_df[["type", "subtype"]].drop_duplicates()
```

Some sub subtypes that could exist are: 
| Type | Subtype | Sub Subtype |
| -----|---------| ------------ |
| ACCIDENT | MAJOR | UNCLASSIFIED |
| ACCIDENT | MINOR | UNCLASSIFIED |
| HAZARD | ROAD | CAR_STOPPED |
| HAZARD | ROAD | CONSTRUCTION |
| HAZARD | ROAD | EMERGENCY_VEHICLE |
| HAZARD | ROAD | ICE |
| HAZARD | ROAD | OBJECT |
| HAZARD | ROAD | POT_HOLE |
| HAZARD | ROAD | LANE_CLOSED |
| HAZARD | ROAD | TRAFFIC_LIGHT_FAULT |
| HAZARD | ROAD | ROAD_KILL |
| HAZARD | SHOULDER | CAR_STOPPED |
| HAZARD | SHOULDER | ANIMALS |
| HAZARD | SHOULDER | MISSING_SIGN |
| HAZARD | WEATHER | FLOOD |
| HAZARD | WEATHER | FOG |
| HAZARD | WEATHER | HEAVY_SNOW |
| HAZARD | WEATHER | HAIL |
| JAM | HEAVY | UNCLASSIFIED |
| JAM | MODERATE | UNCLASSIFED |
| JAM | STAND_STILL | UNCLASSIFED |
| JAM | LIGHT | UNCLASSIFED |
| ROAD_CLOSED | HAZARD | UNCLASSIFED |
| ROAD_CLOSED | CONSTRUCTION | UNCLASSIFIED |
| ROAD_CLOSED | EVENT | UNCLASSIFED |

I think that we should keep the NA subtypes. These are important because just because there is no classified sub-subtype does not mean that there is an event on the road that we should note. It just may be that the event was not fully classified, but that makes it no less important to our data. 

4. 

```{python}
#make a new df
update_waze = pd.DataFrame({
  "type": combo["type"],
  "subtype": combo["subtype"], 
  "updated_type": combo["type"],
  "updated_subtype": ["UNCLASSIFIED", "UNCLASSIFIED", "UNCLASSIFED", "UNCLASSIFIED", "MAJOR", "MINOR", "ON_ROAD", "ON_ROAD", "ON_ROAD", "ON_ROAD", "ON_ROAD","ON_ROAD","ON_ROAD","ON_ROAD","ON_SHOULDER", "ON_SHOULDER", "WEATHER", "WEATHER", "HEAVY", "MODERATE", "STAND_STILL", "EVENT", "ON_ROAD", "WEATHER", "CONSTRUCTION", "ON_ROAD", "ON_SHOULDER", "ON_SHOULDER", "LIGHT", "WEATHER", "HAZARD", "WEATHER"],
  "updated_subsubtype": ["UNCLASSIFED","UNCLASSIFED", "UNCLASSIFED", "UNCLASSIFED", "UNCLASSIFED", "UNCLASSIFED", "UNCLASSIFED", "CAR_STOPPED", "CONSTRUCTION", "EMERGENCY", "ICE", "OBJECT", "POT_HOLE", "TRAFFIC_LIGHT_FAULT", "UNCLASSIFED", "CAR_STOPPED", "UNCLASSIFED", "FLOOD", "UNCLASSIFED", "UNCLASSIFED", "UNCLASSIFED", "UNCLASSIFED", "LANE_CLOSED", "FOG", "CONSTRUCTION", "ROAD_KILL", "ANIMALS", "MISSING_SIGN","UNCLASSIFED", "HEAVY_SNOW", "HAZARD", "HAIL"]
})
```


```{python}
#merge the crosswalk with the original data 
waze_df= waze_df.merge(update_waze, on=["type", "subtype"], how="left")
```

```{python}
#convert any NA's to UNCLASSIFIED
waze_df[["updated_type", "updated_subtype", "updated_subsubtype"]] = waze_df[["updated_type", "updated_subtype", "updated_subsubtype"]].fillna("UNCLASSIFIED")
```

```{python}
#count the number of rows where accident is unclassified
waze_df[(waze_df["updated_type"] == "ACCIDENT") & (waze_df["updated_subtype"] == "UNCLASSIFIED")].shape[0]
```

There are 24,359 instance where accident has an unclassifed subtype.

# App #1: Top Location by Alert Type Dashboard (30 points){-}

1. 

a. 
```{python}
import re
```

```{python}
#make the regex pattern
pattern = r"POINT\(([-+]?\d*\.\d+|\d+) ([-+]?\d*\.\d+|\d+)\)"

# Apply the regex to each element in the geo column
waze_df[["longitude", "latitude"]] = waze_df["geo"].apply(
    lambda x: pd.Series(re.search(pattern, x).groups() if re.search(pattern, x) else (None, None))
).astype(float)
```

I used Chatgpt to help me with this. This was my prompt: use regex to extract the latitude and longitude from a variable that is written in wkt with the structure POINT(latitude longitude)

b. 
```{python}
#Change the number of decimal places for latitude and longitude 
waze_df[["longitude","latitude"]]= waze_df[["longitude", "latitude"]].round(2)
```

```{python}
#find the binned combinations that have the highest number of observations in the dataset 
lat_lon_combo = waze_df[["longitude", "latitude"]].value_counts().reset_index(name="count")
```

The combination of (-87.65 41.88) has the largest number of observations in the dataset with 21,325.

c. 
```{python}
#create a new column in the waze_df that shows the type and subtype for selection 
waze_df["type_subtype"] = waze_df["updated_type"] + " - " + waze_df["updated_subtype"]
```

```{python}
# Group the df
grouped = waze_df.groupby(["type_subtype", "latitude", "longitude"]).size().reset_index(name="count")

# Sort values 
grouped_sorted = grouped.sort_values(by=["type_subtype", "count"], ascending=[True, False])

# Get top 10 latitude-longitude pairs for each 'type_subtype'
top_alerts_map = grouped_sorted.groupby("type_subtype").head(10)
```

```{python}
len(top_alerts_map)
```

```{python}
#save this data as a csv called top_alerts_map 
output_dir = "top_alerts_map"

top_alerts_map.to_csv(os.path.join(output_dir, "top_alerts_map.csv"), index=False)
```


The level of aggregation for this data is to the point of looking at latitude and longitude within a certain combination of type and subtype. This dataframe has 155 observations

2.  
```{python}
#subset out heavy traffic jams
heavy_traffic = waze_df[(waze_df["updated_type"] == "JAM") & (waze_df["updated_subtype"] == "HEAVY")]
```

```{python}
#find the top 10 bins with the highest number of alerts for this type and subtype 
heavy_traffic_latlon = heavy_traffic[["longitude", "latitude"]].value_counts().reset_index(name="count").sort_values(by = "count", ascending = False).head(10)
```

```{python}
#create a scatter plot 
alt.Chart(heavy_traffic_latlon).mark_circle().encode(
  x = alt.X("longitude:Q", scale=alt.Scale(domain = [-87.95, -87.52])),
  y = alt.Y("latitude:Q", scale=alt.Scale(domain=[41.6, 42.05])),
  size = alt.Size("count:Q", legend=alt.Legend(title="Number of Alerts"))).properties(
  title = "Ten Highest Number of Heavy Traffic Jams Latitude and Longitude")
```

3. 
    
a. 
```{python}
# load in the neighborhood data
file_path = "./top_alerts_map/Boundaries - Neighborhoods.geojson"
```
    

b. 
```{python}
with open(file_path) as f:
  chicago_geojson = json.load(f)

geo_data = alt.Data(values=chicago_geojson["features"])
```

4. 
```{python}
#load in the map of the chicago neighborhoods
chi_map = alt.Chart(geo_data).mark_geoshape(
    fillOpacity=0,  
    stroke="black"  
).encode().project(
    type="identity",
    reflectY=True
).properties(
  width = 600, 
  height = 600
)
```

```{python}
#edit the scatter plot made before with the new axis
heavy_traffic_chart = alt.Chart(heavy_traffic_latlon).mark_circle().encode(
  x = alt.X("longitude:Q", scale=alt.Scale(domain = [-87.95, -87.52])),
  y = alt.Y("latitude:Q", scale=alt.Scale(domain=[41.6, 42.05])),
  size = alt.Size("count:Q", legend=alt.Legend(title="Number of Alerts"))).properties(
  title = "Ten Highest Number of Heavy Traffic Jams")
```

```{python}
#layer the scatter and chicago map 
chi_map + heavy_traffic_chart
```

5. 
a. 
```{python}
choices = waze_df["type_subtype"].unique()
```

![Dropdown Image](dropdown.png)

There are 16 type/subtype combinations in my dropdown menu.

b. 
![Jam-Heavy Image](jam_heavy.png)

c. 
![Road Closed for Event](closed_event.png)

Road closured due to events are the most common in the northern part of Chicago.

d. 
Question: Are weather hazards pretty dispered across the city or concentrated in a particular area? 

Answer: Weather hazards are pretty dispersed throughout the city. 

![Weather Hazard Disperal](weather_hazard.png)

e. 
Another column that could be added to the dashboard to enhance our analysis could be the subsubtype column. This could allow us to look into specific kinds of alerts that may not be fully encompassed by just the type and subtype.

# App #2: Top Location by Alert Type and Hour Dashboard (20 points) {-}

1. 

a. 
No, I do not think this would be a good idea. There are so many time stamps and very few that would overlap to be able to make a group. The data would likely remain unchanged if we did this. 

    
b. 

```{python}
#convert timestamp to dt 
waze_df["ts"] = pd.to_datetime(waze_df["ts"])
```

```{python}
#create a new column called hour taking the hour from the ts column 
waze_df["hour"] = waze_df["ts"].dt.hour
```

```{python}
#plot the top ten locations by hour 
# Group the df
hour = waze_df.groupby(["hour", "type_subtype", "latitude", "longitude"]).size().reset_index(name="count")

# Sort values 
hour_sorted = hour.sort_values(by=["hour", "count"], ascending=[True, False])

# Get top 10 latitude-longitude pairs for each 'type_subtype'
top_alerts_map_byhour= hour_sorted.groupby("hour").head(10)
```

```{python}
len(top_alerts_map_byhour)
```

```{python}
#save this data as a csv called top_alerts_map 
output_dir2 = "top_alerts_map_byhour"

top_alerts_map_byhour.to_csv(os.path.join(output_dir2, "top_alerts_map_byhour.csv"), index=False)
```

This dataset has 240 rows. 
c.

```{python}
#subset out the heavy traffic from the big plot
heavy_traffic_hour = waze_df[(waze_df["type_subtype"] == "JAM - HEAVY")]
```

```{python}
#find the top ten locations for heavy traffic jams by hour for hour 5, 10, and 15
heavy_traffic_hour = heavy_traffic_hour.groupby(["hour", "type_subtype", "latitude", "longitude"]).size().reset_index(name="count").sort_values(by=["hour", "count"], ascending = [True, False])

heavy_traffic_hour = heavy_traffic_hour[heavy_traffic_hour["hour"].isin([5, 10, 15])]
```

```{python}
heavy_traffic_hour = heavy_traffic_hour.groupby("hour").head(10).reset_index(drop=True)
```

```{python}
#load in the map of the chicago neighborhoods
chi_map = alt.Chart(geo_data).mark_geoshape(
    fillOpacity=0,  
    stroke="black"  
).encode().project(
    type="identity",
    reflectY=True
).properties(
  width = 600, 
  height = 600
)
```

```{python}
#add in the scatter plot
heavy_traffic_hour_plot = alt.Chart(heavy_traffic_hour).mark_circle().encode(
  x = alt.X("longitude:Q", scale=alt.Scale(domain = [-87.95, -87.52])),
  y = alt.Y("latitude:Q", scale=alt.Scale(domain=[41.6, 42.05])),
  size = alt.Size("count:Q", legend=alt.Legend(title="Number of Alerts")), 
  color = alt.Color("hour:N", legend = alt.Legend(title = "Hour"))).properties(
  title = "Ten Highest Number of Heavy Traffic Jams at 5AM, 10AM, and 3PM")
```

```{python}
#layer the scatter and chicago map 
chi_map + heavy_traffic_hour_plot
```

2.

a. 
![UI](ui.png)

b. 
![5am Plot](5.png)

![10am Plot](10.png)

![3pm Plot](3.png)

c. 
Road construction seems to be done more in the morning hours, however in the evening hours alerts seem to be more concentrated in specific areas. 

![7am construction on roads](morning.png)

![6pm construction on roads](evening.png)

# App #3: Top Location by Alert Type and Hour Dashboard (20 points){-}

1. 

a. 
Yes, it will make our data much easier to use in the app if it is already collapsed by range.

b. 

```{python}
hour_bins = [0, 6, 9, 12, 15, 18, 21, 24] 
hour_labels = ["0-6", "6-9", "9-12", "12:00-15:00", "15:00-18:00", "18:00-21:00", "21:00-00:00"]

# Create a new column 'hour_range' that groups the hours into the defined ranges
waze_df["hour"] = pd.cut(waze_df["hour"], bins=hour_bins, labels=hour_labels, right=False)
```

```{python}
#group the hour range and number of alerts together
slider_df = waze_df.groupby(["hour", "type_subtype", "latitude", "longitude"]).size().reset_index(name="count")

# Sort values 
slider_sorted = slider_df.sort_values(by=["hour", "count"], ascending=[True, False])

# Get top 10 latitude-longitude pairs for each 'type_subtype'
top_alerts_map_byhour_sliderrange= slider_sorted.groupby("hour").head(10)
```


```{python}
#save this data as a csv 
output_dir3 = "top_alerts_map_byhour_sliderrange"

top_alerts_map_byhour_sliderrange.to_csv(os.path.join(output_dir3, "top_alerts_map_byhour_sliderrange.csv"), index=False)
```

```{python}
#create the df for the heavy traffic jams between 6 and 9 am 
morn_range = waze_df[waze_df["hour"] == "06:00-09:00"]
```

```{python}
#find the 10 highest number of alerts per area
morn_range = heavy_traffic_hour.groupby(["type_subtype", "latitude", "longitude"]).size().reset_index(name="count").sort_values(by=["count"], ascending = [False]).head(10)
```

```{python}
#create the plot
plot_6_9 = alt.Chart(morn_range).mark_circle().encode(
  x = alt.X("longitude:Q", scale=alt.Scale(domain = [-87.95, -87.52])),
  y = alt.Y("latitude:Q", scale=alt.Scale(domain=[41.6, 42.05])),
  size = alt.Size("count:Q", legend=alt.Legend(title="Number of Alerts"))).properties(
  title = "Ten Highest Number of Heavy Traffic Jams Between 6AM and 9AM")
```

```{python}
#layer the scatter and chicago map 
chi_map + plot_6_9
```


2. 

a. 
![Slider Range UI and Plot](2aui.png)

b. 
    
3. 

a. 
    

b. 


c. 


d.
